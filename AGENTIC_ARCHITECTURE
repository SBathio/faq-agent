Hereâ€™s your complete AGENTIC_ARCHITECTURE.md file in Markdown format:

â¸»


# ğŸ¤– FAQ Agentic System â€“ LangChain Agent Architecture

This document outlines the full architecture of the `faq-agent` system, which uses **LangChain Agents**, a retrieval-augmented generation (RAG) pipeline, and custom tools to provide intelligent FAQ responses with citations.

---

## ğŸ§  Overview

- **Tech Stack:** FastAPI, LangChain, OpenAI, FAISS (or similar)
- **LLM Framework:** LangChain AgentExecutor with `create_openai_functions_agent`
- **Key Features:** Tool use, retrieval context, dynamic prompts, OpenAI functions

---

## ğŸ“ˆ System Flow Diagram

```text
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      FastAPI Server       â”‚
        â”‚ (main.py + api/routes.py) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ POST /ask endpoint â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                   â–¼                          â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
      â”‚ run_agent(query: str)    â”‚            â”‚
      â”‚ from agent_executor.py   â”‚            â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
               â”‚                              â”‚
               â–¼                              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
    â”‚ LangChain AgentExecutor       â”‚         â”‚
    â”‚ - created via                â”‚          â”‚
    â”‚   create_openai_functions_agent()       â”‚
    â”‚ - initialized w/ Tool: search_faq_tool  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
             â–¼                                â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
 â”‚ Tool: search_faq_tool()     â”‚              â”‚
 â”‚ - calls get_top_k_chunks()  â”‚              â”‚
 â”‚ - builds prompt from template             â”‚
 â”‚ - retrieves top K docs       â”‚            â”‚
 â”‚ - formats prompt             â”‚            â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
          â–¼                                   â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
  â”‚ Prompt sent to LLM (OpenAI)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Agent returns final output   â”‚
  â”‚ + relevant source metadata   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ JSON Response to User        â”‚
  â”‚ query + answer + sources     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â¸»

ğŸ§© Module Breakdown

Module	Description
main.py	Initializes the FastAPI app and mounts the /ask route
api/routes.py	Defines the /ask POST route and calls run_agent()
agent/agent_executor.py	Creates the LangChain Agent using create_openai_functions_agent()
agent/faq_agent.py	Re-exports the agent runner for easy import
rag/retriever.py	Retrieves top-K chunks from a FAISS vectorstore
models/prompt_template.py	Houses style-specific prompt formatting logic
utils/config.py	Loads .env configs (OpenAI API key, model name, etc.)


â¸»

ğŸ› ï¸ LangChain Tools

ğŸ”§ SearchFAQ Tool
	â€¢	Purpose: Retrieve and format top-k matching FAQs
	â€¢	Functionality:
	â€¢	Accepts a query
	â€¢	Searches vector store for relevant context
	â€¢	Returns formatted prompt and citations

â¸»

ğŸ§  Agent Strategy
	â€¢	Uses create_openai_functions_agent() to create an OpenAI function-call capable agent
	â€¢	Loads default system prompt from:

langchain hub: hwchase17/openai-functions-agent


	â€¢	Powered by langchain-openai.ChatOpenAI

â¸»

ğŸ“¥ Input â†’ ğŸ“¤ Output Format

Request

POST /ask
{
  "query": "How do I request a refund?",
  "style": "default"
}

Response

{
  "query": "How do I request a refund?",
  "answer": "You can request a refund by emailing support within 30 days.",
  "sources": [
    {
      "source": "refund_policy.txt",
      "content": "To request a refund, please contact support@domain.com within 30 days."
    }
  ]
}


â¸»

ğŸ§° Future Extensions

Feature	Status	Notes
âœ… Tool Integration	Done	SearchFAQ Tool
âœ… OpenAI Function Agent	Done	Uses create_openai_functions_agent()
â³ Memory / Chat History	In Progress	Will use ConversationBufferMemory or Redis-backed store
â³ Multi-Tool Agent	Planned	Add tools like web_search, db_lookup, ticket_creator, etc.
â³ LangGraph Support	Planned	For stateful workflows (LangGraph + LangChain v0.3+)


â¸»

ğŸ§ª Local Run Command

uvicorn main:app --reload

Access the FastAPI app at: http://127.0.0.1:8000/docs

â¸»

ğŸ“ Related Files
	â€¢	.env.example â€“ API keys and model configs
	â€¢	requirements.txt â€“ pinned working versions
	â€¢	README.md â€“ project overview
	â€¢	AGENTIC_ARCHITECTURE.md â€“ system flow and logic (this file)

â¸»

Maintained by SBathio â€“ GitHub: github.com/SBathio

---

Would you like me to:
- ğŸ’¾ Save this as a `AGENTIC_ARCHITECTURE.md` file in your project?
- ğŸ–¼ Generate a PNG version of the diagram?
- ğŸ§© Add sections for LangGraph or multi-agent orchestration?

Let me know whatâ€™s next.